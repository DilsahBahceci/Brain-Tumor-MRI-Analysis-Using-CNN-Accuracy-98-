{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proje Ã–zeti\n\n## Dataset HakkÄ±nda\n- Bu Ã§alÄ±ÅŸmada kullanÄ±lan veri seti: [Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data)  \n- Veri seti **4 sÄ±nÄ±ftan oluÅŸmaktadÄ±r**:  \n  - **Glioma**  \n  - **Meningioma**  \n  - **Pituitary**  \n  - **No Tumor**  \n- Toplamda **7,023 MRI gÃ¶rÃ¼ntÃ¼sÃ¼** iÃ§ermektedir. GÃ¶rseller farklÄ± boyutlarda olup gri/renkli varyasyonlar barÄ±ndÄ±rmaktadÄ±r.  \n- AmaÃ§: MRI gÃ¶rÃ¼ntÃ¼lerinde **beyin tÃ¼mÃ¶rÃ¼nÃ¼n varlÄ±ÄŸÄ±nÄ± ve tipini sÄ±nÄ±flandÄ±rmak**, bÃ¶ylece medikal gÃ¶rÃ¼ntÃ¼leme alanÄ±nda otomatik bir yardÄ±mcÄ± sistem geliÅŸtirmektir.  \n\n***\n## <span style='border-left: 4px solid #0000FF; padding-left: 10px;'> Ä°Ã§erikler <b>\n\n1. [`Dataset HazÄ±rlÄ±ÄŸÄ±`](#data)\n2. [`SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Analizi ve GÃ¶rselleÅŸtirme`](#imports)\n3. [`CNN Modeli Kurulumu ve Derleme`](#import_data)\n4. [`Model Performans DeÄŸerlendirmesi`](#vis)\n\nAuthor: [DilÅŸah BahÃ§eci](https://www.kaggle.com/dilahbaheci)","metadata":{}},{"cell_type":"markdown","source":"# 1. Dataset HazÄ±rlÄ±ÄŸÄ±\n## 1.1. Brain Tumor MRI Dataset HazÄ±rlÄ±ÄŸÄ±\n\nBu notebook'ta MRI beyin tÃ¼mÃ¶rÃ¼ veri seti (glioma, meningioma, pituitary, notumor) Ã¼zerinde \n**dosya yollarÄ±** ve **etiketleri** toplayÄ±p pandas DataFrame formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.  \n\n- `get_data_labels()` fonksiyonu klasÃ¶r yapÄ±sÄ±nÄ± dolaÅŸarak resim dosyalarÄ±nÄ±n yollarÄ±nÄ± ve etiketlerini Ã§Ä±karÄ±r.  \n- EÄŸitim (`Training`) ve test (`Testing`) klasÃ¶rlerinden veriler ayrÄ± ayrÄ± alÄ±nÄ±r.  \n- SonuÃ§ olarak `train_df` ve `test_df` DataFrameâ€™leri oluÅŸturulur.  \n  - `Path`: Resim dosyasÄ±nÄ±n tam yolu  \n  - `Label`: Resmin ait olduÄŸu sÄ±nÄ±f  \n\nBÃ¶ylece veri seti daha sonra **model eÄŸitimi** ve **analiz** iÃ§in hazÄ±r hale gelir.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef get_data_labels(directory):\n    paths = []\n    labels = []\n    classes = os.listdir(directory)  # klasÃ¶r isimleri: glioma, meningioma, pituitary, notumor\n    \n    for label in classes:\n        class_dir = os.path.join(directory, label)\n        for file in os.listdir(class_dir):\n            file_path = os.path.join(class_dir, file)\n            if file_path.endswith(('.jpg', '.png', '.jpeg')):  # sadece resimleri al\n                paths.append(file_path)\n                labels.append(label)\n    \n    return paths, labels\n\n\ntrain_paths, train_labels = get_data_labels('/kaggle/input/brain-tumor-mri-dataset/Training')\ntest_paths, test_labels = get_data_labels('/kaggle/input/brain-tumor-mri-dataset/Testing')\n\ntrain_df = pd.DataFrame({\"Path\": train_paths,\"Label\": train_labels})\ntest_df = pd.DataFrame({\"Path\": test_paths,\"Label\": test_labels})\n\ntrain_df, test_df.head()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:04:49.910602Z","iopub.execute_input":"2025-09-25T19:04:49.910874Z","iopub.status.idle":"2025-09-25T19:04:49.948360Z","shell.execute_reply.started":"2025-09-25T19:04:49.910854Z","shell.execute_reply":"2025-09-25T19:04:49.947579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2. Etiketlerin SayÄ±sallaÅŸtÄ±rÄ±lmasÄ± (Label Encoding)\n\nBu adÄ±mda, sÄ±nÄ±f etiketlerini (glioma, meningioma, pituitary, notumor) \n**string** formatÄ±ndan **sayÄ±sal** (0, 1, 2, 3) formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.  \n\n- `LabelEncoder` sÄ±nÄ±fÄ± ile string etiketler integer deÄŸerlere Ã§evrilir.  \n- EÄŸitim (`train_labels`) Ã¼zerinde `fit_transform()` uygulanÄ±r, bÃ¶ylece sÄ±nÄ±flar Ã¶ÄŸrenilir.  \n- Test (`test_labels`) Ã¼zerinde `transform()` uygulanÄ±r, aynÄ± mapping kullanÄ±lÄ±r.  \n- Daha sonra `train_df` ve `test_df` DataFrameâ€™leri oluÅŸturularak:  \n  - `Path`: Resim dosyasÄ±nÄ±n yolu  \n  - `Label`: SayÄ±sal sÄ±nÄ±f etiketi  \n  saklanÄ±r.  \n\nSon olarak `head()` fonksiyonu ile ilk birkaÃ§ satÄ±r kontrol edilir.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Label encode (string -> integer)\nle = LabelEncoder()\ntrain_labels_int = le.fit_transform(train_labels)  # 0,1,2,3\ntest_labels_int = le.transform(test_labels)\n\n# DataFrame oluÅŸtur\ntrain_df = pd.DataFrame({\"Path\": train_paths, \"Label\": train_labels_int})\ntest_df = pd.DataFrame({\"Path\": test_paths, \"Label\": test_labels_int})\n\n# Kontrol\nprint(train_df.head())\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:04:49.949651Z","iopub.execute_input":"2025-09-25T19:04:49.949882Z","iopub.status.idle":"2025-09-25T19:04:49.962323Z","shell.execute_reply.started":"2025-09-25T19:04:49.949865Z","shell.execute_reply":"2025-09-25T19:04:49.961653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"'glioma'      â†’ 0\n'meningioma'  â†’ 1\n'notumor'     â†’ 2\n'pituitary'   â†’ 3\n","metadata":{}},{"cell_type":"markdown","source":"## 1.3. GÃ¶rÃ¼ntÃ¼lerin NumPy Dizisine Ã‡evrilmesi\n\nBu adÄ±mda, DataFrame iÃ§erisindeki resim yollarÄ± kullanÄ±larak resimler yÃ¼klenir, \nÃ¶n iÅŸleme tabi tutulur ve model iÃ§in hazÄ±r hale getirilir.  \n\n- `load_img`: Resimleri belirtilen hedef boyuta (`128x128`) ve gri tonlamalÄ± (grayscale) olarak yÃ¼kler.  \n- `img_to_array`: YÃ¼klenen resmi NumPy dizisine Ã§evirir.  \n- Normalizasyon: Piksel deÄŸerleri **0-255** aralÄ±ÄŸÄ±ndan **0-1** aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  \n- Etiketler (`Label` sÃ¼tunu) `class_names` listesine gÃ¶re integer deÄŸerine Ã§evrilir.  \n- SonuÃ§:  \n  - `X_train`, `X_test`: Resim verileri (NumPy dizisi)  \n  - `y_train`, `y_test`: SayÄ±sal sÄ±nÄ±f etiketleri  \n\nSon olarak `X_train.shape` ile eÄŸitim setinin boyutu kontrol edilir.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\n\nIMG_SIZE = (128, 128)  # model input boyutu\n\ndef df_to_arrays(df, class_names):\n    X = []\n    y = []\n    for path, label in zip(df['Path'], df['Label']):\n        img = load_img(path, target_size=IMG_SIZE, color_mode='grayscale')   # resimleri hedef boyuta getir\n        img_array = img_to_array(img) / 255.0        # normalize [0,1]\n        X.append(img_array)\n        y.append(class_names.index(label))           # string label â†’ integer\n    return np.array(X), np.array(y)\n\n\nCLASS_TYPES = [3, 2, 1, 0]\n\nX_train, y_train = df_to_arrays(train_df, CLASS_TYPES)\nX_test, y_test = df_to_arrays(test_df, CLASS_TYPES)\n\nprint(X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:04:49.963078Z","iopub.execute_input":"2025-09-25T19:04:49.963356Z","iopub.status.idle":"2025-09-25T19:05:53.211852Z","shell.execute_reply.started":"2025-09-25T19:04:49.963324Z","shell.execute_reply":"2025-09-25T19:05:53.211073Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Analizi ve GÃ¶rselleÅŸtirme\n## 2.1. Ã–rnek GÃ¶rselleri GÃ¶sterme\n\n- `LabelEncoder` ile string etiketler sayÄ±sal deÄŸerlere (`0, 1, 2, 3`) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.\n- SÄ±nÄ±f isimleri `class_names` deÄŸiÅŸkenine alÄ±ndÄ± (`glioma`, `meningioma`, `notumor`, `pituitary`).\n- `show_sample_images` fonksiyonu kullanÄ±larak her sÄ±nÄ±ftan 3 rastgele gÃ¶rsel seÃ§ildi ve gÃ¶sterildi:\n  - Ã–nce **train seti** iÃ§in Ã¶rnekler gÃ¶rÃ¼ntÃ¼lendi.\n  - ArdÄ±ndan **test seti** iÃ§in Ã¶rnekler gÃ¶sterildi.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\n\ndef show_sample_images(df, class_names, num_samples=3, img_size=(128,128)):\n    for cls_idx, cls_name in enumerate(class_names):\n        class_images = df[df['Label'] == cls_idx]['Path'].tolist()\n        if len(class_images) == 0:\n            continue\n        sample_paths = random.sample(class_images, min(num_samples, len(class_images)))\n        \n        plt.figure(figsize=(15,5))\n        for i, img_path in enumerate(sample_paths):\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, img_size)\n            \n            plt.subplot(1, num_samples, i+1)\n            plt.imshow(img, cmap='gray')\n            plt.axis('off')\n            plt.title(f\"{cls_name}\")\n        plt.show()\n\n# Ã–rnek: train_df['Label'] string ise Ã¶nce encode et\nle = LabelEncoder()\ntrain_df['Label'] = le.fit_transform(train_df['Label'])\ntest_df['Label'] = le.transform(test_df['Label'])\n\n# SÄ±nÄ±f isimlerini al\nclass_names = le.classes_   # ['glioma','meningioma','notumor','pituitary']\n\nshow_sample_images(train_df, class_names, num_samples=3)\nshow_sample_images(test_df, class_names, num_samples=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:53.213825Z","iopub.execute_input":"2025-09-25T19:05:53.214890Z","iopub.status.idle":"2025-09-25T19:05:55.609629Z","shell.execute_reply.started":"2025-09-25T19:05:53.214860Z","shell.execute_reply":"2025-09-25T19:05:55.608788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2. SÄ±nÄ±f BazÄ±nda Train/Test DaÄŸÄ±lÄ±mÄ± Analizi(Pie Chart)\n\nBu adÄ±mda her bir sÄ±nÄ±f iÃ§in (glioma, meningioma, notumor, pituitary) \n**eÄŸitim ve test veri daÄŸÄ±lÄ±mlarÄ±** gÃ¶rselleÅŸtirilir.  \n\n- `class_names`: Etiket isimleri (`['glioma','meningioma','notumor','pituitary']`).  \n- `class_indices`: Her sÄ±nÄ±fa karÅŸÄ±lÄ±k gelen integer deÄŸerler (`[0,1,2,3]`).  \n- DÃ¶ngÃ¼ ile her sÄ±nÄ±f iÃ§in:  \n  - EÄŸitim setindeki Ã¶rnek sayÄ±sÄ± (`train_count`).  \n  - Test setindeki Ã¶rnek sayÄ±sÄ± (`test_count`).  \n  - Toplam Ã¶rnek sayÄ±sÄ± (`total`).  \n- **Pie chart**: EÄŸitim ve test oranlarÄ±nÄ± yÃ¼zde ve adet bazÄ±nda gÃ¶sterir.  \n\nSonuÃ§: Her sÄ±nÄ±f iÃ§in ayrÄ± ayrÄ± `Train/Test` daÄŸÄ±lÄ±mlarÄ±nÄ± gÃ¶rselleÅŸtire\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# SÄ±nÄ±f isimleri ve integer karÅŸÄ±lÄ±klarÄ±\nclass_names = le.classes_      # ['glioma','meningioma','notumor','pituitary']\nclass_indices = range(len(class_names))  # [0,1,2,3]\n\n# Her sÄ±nÄ±f iÃ§in pie chart\nfor cls_idx, cls_name in zip(class_indices, class_names):\n    train_count = (train_df['Label'] == cls_idx).sum()\n    test_count = (test_df['Label'] == cls_idx).sum()\n    total = train_count + test_count\n    \n    if total == 0:\n        print(f\"{cls_name} sÄ±nÄ±fÄ±nda veri yok, atlanÄ±yor.\")\n        continue\n    \n    sizes = [train_count, test_count]\n    labels = [f'Train ({train_count} / {total}, {train_count/total*100:.1f}%)',\n              f'Test ({test_count} / {total}, {test_count/total*100:.1f}%)']\n    \n    plt.figure(figsize=(5,5))\n    plt.pie(sizes, labels=labels, autopct='', startangle=90, colors=['skyblue', 'lightgreen'])\n    plt.title(f\"{cls_name} sÄ±nÄ±fÄ± - Train/Test daÄŸÄ±lÄ±mÄ±\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:55.610659Z","iopub.execute_input":"2025-09-25T19:05:55.610951Z","iopub.status.idle":"2025-09-25T19:05:55.969208Z","shell.execute_reply.started":"2025-09-25T19:05:55.610928Z","shell.execute_reply":"2025-09-25T19:05:55.968447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3. EÄŸitim ve Test Seti SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Analizi(Pie Chart)\n\nBu adÄ±mda eÄŸitim ve test veri setlerindeki **sÄ±nÄ±f yÃ¼zdeleri** \npasta grafikleri ile gÃ¶rselleÅŸtirilir.  \n\n- `train_counts` / `test_counts`: Her sÄ±nÄ±ftaki Ã¶rnek sayÄ±larÄ±.  \n- `train_percent` / `test_percent`: Her sÄ±nÄ±fÄ±n toplam veri iÃ§indeki yÃ¼zdesi.  \n- `class_names`: Etiket isimleri (`glioma, meningioma, notumor, pituitary`).  \n- Ä°ki ayrÄ± subplot oluÅŸturulur:  \n  - **Sol grafik**: EÄŸitim seti sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±  \n  - **SaÄŸ grafik**: Test seti sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±  \n\nSonuÃ§: EÄŸitim ve test setlerindeki sÄ±nÄ±f dengesizlikleri kolayca karÅŸÄ±laÅŸtÄ±rÄ±labilir.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# EÄŸitim seti yÃ¼zdeleri\ntrain_counts = train_df['Label'].value_counts().sort_index()\ntrain_percent = (train_counts / len(train_df) * 100).round(2)\nclass_names = le.classes_\n\n# Test seti yÃ¼zdeleri\ntest_counts = test_df['Label'].value_counts().sort_index()\ntest_percent = (test_counts / len(test_df) * 100).round(2)\n\n# Pasta grafikleri\nplt.figure(figsize=(12,6))\n\n# Train set\nplt.subplot(1,2,1)\nplt.pie(train_percent, labels=class_names, autopct='%1.1f%%', startangle=90, colors=['skyblue','salmon','lightgreen','orange'])\nplt.title('Train Set SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±')\n\n# Test set\nplt.subplot(1,2,2)\nplt.pie(test_percent, labels=class_names, autopct='%1.1f%%', startangle=90, colors=['skyblue','salmon','lightgreen','orange'])\nplt.title('Test Set SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:55.970119Z","iopub.execute_input":"2025-09-25T19:05:55.970361Z","iopub.status.idle":"2025-09-25T19:05:56.145307Z","shell.execute_reply.started":"2025-09-25T19:05:55.970344Z","shell.execute_reply":"2025-09-25T19:05:56.144465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Soldaki pie chart, **Train setindeki** sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steriyor.  \n  - `notumor` sÄ±nÄ±fÄ± en yÃ¼ksek oran (%27.9) ile Ã¶ne Ã§Ä±kÄ±yor.  \n  - DiÄŸer sÄ±nÄ±flar (`glioma`, `meningioma`, `pituitary`) yaklaÅŸÄ±k olarak %23-25 oranÄ±nda.  \n\n- SaÄŸdaki pie chart, **Test setindeki** sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steriyor.  \n  - `notumor` sÄ±nÄ±fÄ± yine en yÃ¼ksek oran (%30.9).  \n  - DiÄŸer sÄ±nÄ±flar (%22-23 civarÄ±) neredeyse eÅŸit daÄŸÄ±lÄ±m gÃ¶stermekte.  \n\n- **Genel yorum:** Hem train hem test setlerinde sÄ±nÄ±flar nispeten dengeli daÄŸÄ±lmÄ±ÅŸ, `notumor` sÄ±nÄ±fÄ± biraz daha fazla temsil edilmiÅŸ. Bu, sÄ±nÄ±f dengesizliÄŸinin minimal olduÄŸunu gÃ¶steriyor ve model eÄŸitimi iÃ§in olumlu bir durum.  \n","metadata":{}},{"cell_type":"markdown","source":"# 3.CNN Modeli Kurulumu ve Derleme\n\nBu adÄ±mda beyin tÃ¼mÃ¶rÃ¼ sÄ±nÄ±flandÄ±rmasÄ± iÃ§in bir **Convolutional Neural Network (CNN)** modeli tanÄ±mlanÄ±r.  \n\n### Model Mimarisi\n- **Girdi katmanÄ±**: `(128,128,1)` boyutunda gri Ã¶lÃ§ekli resimler.  \n- **KonvolÃ¼syon + MaxPooling katmanlarÄ±**:  \n  - Conv2D(32 filtre) + MaxPooling2D  \n  - Conv2D(64 filtre) + MaxPooling2D  \n  - Conv2D(128 filtre) + MaxPooling2D  \n- **Flatten**: Ã‡ok boyutlu Ã§Ä±ktÄ±yÄ± dÃ¼zleÅŸtirir.  \n- **Dense (Tam baÄŸlÄ± katman)**: 128 nÃ¶ron + ReLU aktivasyonu.  \n- **Dropout (0.5)**: Overfittingâ€™i azaltmak iÃ§in rastgele nÃ¶ronlarÄ± kapatÄ±r.  \n- **Ã‡Ä±kÄ±ÅŸ katmanÄ±**: `num_classes` nÃ¶ron, Softmax aktivasyonu (Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma).  \n\n### Ã–ÄŸrenme OranÄ± DÃ¼zenleme\n- `ReduceLROnPlateau`: Valide kaybÄ± (`val_loss`) iyileÅŸmediÄŸinde Ã¶ÄŸrenme oranÄ±nÄ± yarÄ±ya indirir.  \n\n### Derleme\n- **Optimizer**: Adam (learning rate = 0.001)  \n- **Loss**: `sparse_categorical_crossentropy` (etiketler integer olduÄŸu iÃ§in)  \n- **Metrik**: Accuracy  \n\nSon olarak `model.summary()` ile modelin katman yapÄ±sÄ± ve parametre sayÄ±larÄ± gÃ¶rÃ¼ntÃ¼lenir.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# SÄ±nÄ±f sayÄ±sÄ±\nnum_classes = len(CLASS_TYPES)\n\n# Modeli oluÅŸtur\nmodel = Sequential([\n    # 1. Conv + Pool\n    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n    MaxPooling2D((2,2)),\n\n    # 2. Conv + Pool\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n\n    # 3. Conv + Pool\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n\n    # Flatten ve Dense katmanlarÄ±\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),  # overfitting'i azaltmak iÃ§in\n    Dense(num_classes, activation='softmax')  # sÄ±nÄ±f sayÄ±sÄ± kadar Ã§Ä±ktÄ±\n])\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',   # val_accuracy de seÃ§ebilirsin\n    factor=0.5,           # LRâ€™i yarÄ±ya indir\n    patience=2,           # 2 epoch boyunca geliÅŸme yoksa uygula\n    min_lr=1e-6           # minimum LR sÄ±nÄ±rÄ±\n)\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\n\n# Model Ã¶zeti\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:56.146211Z","iopub.execute_input":"2025-09-25T19:05:56.146707Z","iopub.status.idle":"2025-09-25T19:05:56.574716Z","shell.execute_reply.started":"2025-09-25T19:05:56.146688Z","shell.execute_reply":"2025-09-25T19:05:56.574058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.1. EÄŸitim Setini EÄŸitim ve Validation Olarak BÃ¶lme\n\nBu adÄ±mda, mevcut **eÄŸitim verileri** (`X_train`, `y_train`) iÃ§erisinden %10â€™u \n**validation seti** olarak ayrÄ±lÄ±r.  \n\n- `test_size=0.1`: EÄŸitim setinin %10â€™u validation setine ayrÄ±lÄ±r.  \n- `random_state=42`: AynÄ± bÃ¶lÃ¼nmenin tekrar Ã¼retilebilmesi iÃ§in sabit deÄŸer.  \n- `stratify=y_train`: EÄŸitim ve validation setinde sÄ±nÄ±f daÄŸÄ±lÄ±mlarÄ±nÄ±n korunmasÄ±nÄ± saÄŸlar.  \n\nSonuÃ§ olarak:  \n- `X_train_new`, `y_train_new`: Yeni eÄŸitim seti (%90)  \n- `X_val`, `y_val`: Validation seti (%10)  \n\nSon satÄ±rda setlerin boyutlarÄ± ekrana yazdÄ±rÄ±larak kontrol edilir.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Train setini %90 eÄŸitim, %10 validation olarak ayÄ±r\nX_train_new, X_val, y_train_new, y_val = train_test_split(\n    X_train, y_train, \n    test_size=0.1,      # %10 validation\n    random_state=42,    # tekrar Ã¼retilebilirlik iÃ§in sabit sayÄ±\n    stratify=y_train    # sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± korumak iÃ§in\n)\n\nprint(\"Yeni eÄŸitim seti:\", X_train_new.shape, y_train_new.shape)\nprint(\"Validation seti:\", X_val.shape, y_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:56.575443Z","iopub.execute_input":"2025-09-25T19:05:56.575691Z","iopub.status.idle":"2025-09-25T19:05:56.757947Z","shell.execute_reply.started":"2025-09-25T19:05:56.575665Z","shell.execute_reply":"2025-09-25T19:05:56.757224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2. Modelin EÄŸitimi\n\nBu adÄ±mda CNN modeli eÄŸitim verileri Ã¼zerinde eÄŸitilir.  \n\n- **`model.fit()` parametreleri**:  \n  - `X_train, y_train`: EÄŸitim verileri.  \n  - `validation_data=(X_test, y_test)`: Test seti doÄŸrulama iÃ§in kullanÄ±lÄ±r. (Alternatif olarak validation seti kullanÄ±labilir.)  \n  - `epochs=20`: EÄŸitim 20 epoch boyunca devam eder.  \n  - `callbacks=[reduce_lr]`: `ReduceLROnPlateau` callbackâ€™i, doÄŸrulama kaybÄ± iyileÅŸmezse Ã¶ÄŸrenme oranÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r.  \n\nSonuÃ§ olarak, eÄŸitim sÃ¼reci `history` deÄŸiÅŸkeninde saklanÄ±r. Bu deÄŸiÅŸken daha sonra loss/accuracy grafiklerini Ã§izmek iÃ§in kullanÄ±labilir.\n","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=20,\n    callbacks=[reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:05:56.758770Z","iopub.execute_input":"2025-09-25T19:05:56.759076Z","iopub.status.idle":"2025-09-25T19:31:49.022547Z","shell.execute_reply.started":"2025-09-25T19:05:56.759050Z","shell.execute_reply":"2025-09-25T19:31:49.021690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# EÄŸer modeli kaydetmediysen Ã¶nce kaydet:\nmodel.save(\"my_model.h5\")\n\n# Test setinde performansÄ± Ã¶lÃ§\ntest_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nprint(f\"Test Loss: {test_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:31:49.025422Z","iopub.execute_input":"2025-09-25T19:31:49.025683Z","iopub.status.idle":"2025-09-25T19:31:53.883813Z","shell.execute_reply.started":"2025-09-25T19:31:49.025662Z","shell.execute_reply":"2025-09-25T19:31:53.882809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Model Performans DeÄŸerlendirmesi\n# 4.1. SÄ±nÄ±flandÄ±rma Raporu","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# --- 1. Tahminler ---\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)   # en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± seÃ§\ny_true = y_test                            # zaten label olarak var (1D)\n\n# --- 2. Classification Report ---\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Modelin performans metrikleri oldukÃ§a yÃ¼ksek seviyede. Toplam **1311 Ã¶rnek** Ã¼zerinde test edilmiÅŸ ve **%98 doÄŸruluk (accuracy)** elde edilmiÅŸ. Hem **macro avg** hem de **weighted avg** deÄŸerleri %98 civarÄ±nda olduÄŸundan, modelin farklÄ± sÄ±nÄ±flar arasÄ±nda dengeli bir baÅŸarÄ± gÃ¶sterdiÄŸi sÃ¶ylenebilir.\n\n**SÄ±nÄ±f BazlÄ± SonuÃ§lar**\n- **SÄ±nÄ±f 0**  \n  - Precision: **0.99**, Recall: **1.00**, F1: **1.00**  \n  - Bu sÄ±nÄ±f neredeyse kusursuz sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ. HiÃ§ hata yapÄ±lmamÄ±ÅŸ denebilir.  \n\n- **SÄ±nÄ±f 1**  \n  - Precision: **0.99**, Recall: **1.00**, F1: **0.99**  \n  - Ã‡ok yÃ¼ksek baÅŸarÄ±. BirkaÃ§ kÃ¼Ã§Ã¼k hata dÄ±ÅŸÄ±nda mÃ¼kemmele yakÄ±n.  \n\n- **SÄ±nÄ±f 2**  \n  - Precision: **0.96**, Recall: **0.95**, F1: **0.96**  \n  - Performans diÄŸer sÄ±nÄ±flara gÃ¶re biraz daha dÃ¼ÅŸÃ¼k, Ã¶zellikle recall tarafÄ±nda. Bu, bazÄ± **sÄ±nÄ±f 2 Ã¶rneklerinin yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ±nÄ±** gÃ¶steriyor.  \n\n- **SÄ±nÄ±f 3**  \n  - Precision: **0.97**, Recall: **0.96**, F1: **0.97**  \n  - Gayet baÅŸarÄ±lÄ±, yalnÄ±zca sÄ±nÄ±f 2â€™ye benzer ÅŸekilde birkaÃ§ hata mevcut.  \n\n**Genel Yorum**\n- Model **yÃ¼ksek doÄŸruluk oranÄ±** ve **tÃ¼m sÄ±nÄ±flar iÃ§in dengeli sonuÃ§lar** veriyor.  \n- **SÄ±nÄ±f 2**'de recall deÄŸeri diÄŸer sÄ±nÄ±flara gÃ¶re daha dÃ¼ÅŸÃ¼k olduÄŸundan, model bu sÄ±nÄ±fÄ± ayÄ±rt etmekte biraz zorlanÄ±yor olabilir.  \n- Genel olarak **Ã¼retim iÃ§in kullanÄ±labilir seviyede gÃ¼Ã§lÃ¼ bir model** olduÄŸu sÃ¶ylenebilir.  \n\nğŸ‘‰ Ä°yileÅŸtirme iÃ§in: sÄ±nÄ±f 2â€™ye ait daha fazla veri eklenebilir veya veri dengesizliÄŸi varsa **data augmentation / class weighting** teknikleri denenebilir.\n","metadata":{}},{"cell_type":"markdown","source":"## 4.2.KarÄ±ÅŸÄ±klÄ±k Matriksi","metadata":{}},{"cell_type":"code","source":"# --- 3. Confusion Matrix ---\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n\nplt.xlabel(\"Tahmin Edilen\")   # Predicted\nplt.ylabel(\"GerÃ§ek\")          # True\nplt.title(\"KarÄ±ÅŸÄ±klÄ±k Matrisi\") # Confusion Matrix\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:31:58.951994Z","iopub.execute_input":"2025-09-25T19:31:58.952290Z","iopub.status.idle":"2025-09-25T19:31:59.115999Z","shell.execute_reply.started":"2025-09-25T19:31:58.952264Z","shell.execute_reply":"2025-09-25T19:31:59.115142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. Learning Curves ---\n# Accuracy\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy per Epoch\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:31:59.116788Z","iopub.execute_input":"2025-09-25T19:31:59.117047Z","iopub.status.idle":"2025-09-25T19:31:59.312110Z","shell.execute_reply.started":"2025-09-25T19:31:59.117025Z","shell.execute_reply":"2025-09-25T19:31:59.311186Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3.EÄŸitim ve DoÄŸrulama DoÄŸruluÄŸu (Accuracy) GrafiÄŸi\n\nGrafikte **epoch** sayÄ±sÄ±na karÅŸÄ±lÄ±k eÄŸitim (mavi) ve doÄŸrulama (turuncu) doÄŸruluklarÄ±nÄ±n deÄŸiÅŸimi gÃ¶sterilmektedir.  \n\n- EÄŸitim doÄŸruluÄŸu **hÄ±zlÄ± bir ÅŸekilde artmÄ±ÅŸ** ve 20 epoch sonunda **%99 seviyelerine ulaÅŸmÄ±ÅŸtÄ±r**.  \n- DoÄŸrulama doÄŸruluÄŸu da benzer ÅŸekilde artmÄ±ÅŸ, **%97â€“98 seviyelerine ulaÅŸarak** eÄŸitim doÄŸruluÄŸuna oldukÃ§a yakÄ±n kalmÄ±ÅŸtÄ±r.  \n\n**Yorum**\n- Model, hem eÄŸitim hem de doÄŸrulama setinde yÃ¼ksek doÄŸruluk elde etmiÅŸtir.  \n- **Overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) gÃ¶zlenmemektedir**, Ã§Ã¼nkÃ¼ eÄŸitim ve doÄŸrulama doÄŸruluklarÄ± arasÄ±nda bÃ¼yÃ¼k bir fark yoktur.  \n- EÄŸitimin baÅŸlarÄ±nda (ilk 3-4 epoch) doÄŸrulama eÄŸrisi eÄŸitim eÄŸrisine yakÄ±n seyretmiÅŸ, sonrasÄ±nda da paralel bir ÅŸekilde artmaya devam etmiÅŸtir.  \n- Bu sonuÃ§lar, modelin **genelleme kabiliyetinin gÃ¼Ã§lÃ¼** olduÄŸunu gÃ¶stermektedir.  \n\n**SonuÃ§**\nModel baÅŸarÄ±lÄ± bir ÅŸekilde Ã¶ÄŸrenmiÅŸ ve doÄŸrulama setinde yÃ¼ksek performans sergilemiÅŸtir. Daha fazla epoch denenmesine gerek olmayabilir; mevcut haliyle model Ã¼retim iÃ§in oldukÃ§a uygun gÃ¶rÃ¼nmektedir.\n","metadata":{}},{"cell_type":"code","source":"\n# Loss\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Loss per Epoch\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T19:31:59.312972Z","iopub.execute_input":"2025-09-25T19:31:59.313277Z","iopub.status.idle":"2025-09-25T19:31:59.506419Z","shell.execute_reply.started":"2025-09-25T19:31:59.313252Z","shell.execute_reply":"2025-09-25T19:31:59.505594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4. EÄŸitim ve DoÄŸrulama KayÄ±p (Loss) GrafiÄŸi\n\nGrafikte **epoch** sayÄ±sÄ±na karÅŸÄ±lÄ±k eÄŸitim (mavi) ve doÄŸrulama (turuncu) kayÄ±plarÄ±nÄ±n deÄŸiÅŸimi gÃ¶sterilmektedir.  \n\n- EÄŸitim kaybÄ± (train loss) dÃ¼zenli olarak azalmÄ±ÅŸ ve yaklaÅŸÄ±k **0.01 seviyelerine kadar dÃ¼ÅŸmÃ¼ÅŸtÃ¼r**.  \n- DoÄŸrulama kaybÄ± (validation loss) da genel olarak azalmÄ±ÅŸ, **0.1 civarÄ±nda sabitlenmiÅŸtir**.  \n- EÄŸitim ve doÄŸrulama kayÄ±plarÄ± arasÄ±ndaki fark epoch ilerledikÃ§e biraz artmÄ±ÅŸtÄ±r.  \n\n**Overfitting Analizi**\n- EÄŸer doÄŸrulama kaybÄ±, eÄŸitim kaybÄ±na kÄ±yasla yÃ¼kselip dalgalanma gÃ¶sterseydi **overfitting** iÅŸareti olurdu.  \n- Bu grafikte doÄŸrulama kaybÄ±, eÄŸitim kaybÄ±ndan biraz yÃ¼ksek kalmÄ±ÅŸ olsa da **stabil bir seviyede** devam etmektedir.  \n- DolayÄ±sÄ±yla, **belirgin bir overfitting gÃ¶zlenmemektedir**. KÃ¼Ã§Ã¼k farklar normaldir ve modelin genelleme yapabildiÄŸini gÃ¶sterir.  \n\n**SonuÃ§**\n- Model, eÄŸitim verisini iyi Ã¶ÄŸrenmiÅŸ ve doÄŸrulama verisinde de dÃ¼ÅŸÃ¼k kayÄ±p seviyesine ulaÅŸmÄ±ÅŸtÄ±r.  \n- EÄŸitim ve doÄŸrulama kayÄ±plarÄ± arasÄ±ndaki fark dÃ¼ÅŸÃ¼k olduÄŸu iÃ§in modelin **genelleme baÅŸarÄ±sÄ± yÃ¼ksektir**.  \n- Bu haliyle model, Ã¼retim ortamÄ±nda kullanÄ±labilir durumda gÃ¶rÃ¼nmektedir.\n","metadata":{}}]}